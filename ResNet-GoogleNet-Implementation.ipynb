{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNTu4ymSqnb3qyIsVvgntx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramki13084/Learn-TensorFlow/blob/master/ResNet-GoogleNet-Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_yHGL138G9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "224ca7bf-158e-457c-b7c5-23159120b28d"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend\n",
        "from tf.keras.layers import Concatenate"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-61ee573eecd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8gGB0gv_EQt",
        "outputId": "aac6d320-2ad8-49da-d57b-a339efb6ef9e"
      },
      "source": [
        "!pip install tf-slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf-slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TIv_fE88Ij9"
      },
      "source": [
        "def conv2d_bn(x,\n",
        "              filters,\n",
        "              num_row,\n",
        "              num_col,\n",
        "              padding='same',\n",
        "              strides=(1, 1),\n",
        "              name=None):\n",
        "  \"\"\"Utility function to apply conv + BN.\n",
        "  Args:\n",
        "   1st input x: input tensor.\n",
        "   2nd input filters: filters in `Conv2D`.\n",
        "   3rd input num_row: height of the convolution kernel.\n",
        "   4th input num_col: width of the convolution kernel.\n",
        "   5th input  padding: padding mode in `Conv2D`.\n",
        "   6th input strides: strides in `Conv2D`.\n",
        "    name: name of the ops; will become `name + '_conv'`\n",
        "      for the convolution and `name + '_bn'` for the\n",
        "      batch norm layer.\n",
        "  Returns:\n",
        "    Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "  \"\"\"\n",
        "  if name is not None:\n",
        "    bn_name = name + '_bn'\n",
        "    conv_name = name + '_conv'\n",
        "  else:\n",
        "    bn_name = None\n",
        "    conv_name = None\n",
        "  if backend.image_data_format() == 'channels_first':\n",
        "    bn_axis = 1\n",
        "  else:\n",
        "    bn_axis = 3\n",
        "  x = layers.Conv2D(\n",
        "      filters, (num_row, num_col),\n",
        "      strides=strides,\n",
        "      padding=padding,\n",
        "      use_bias=False,\n",
        "      name=conv_name)(\n",
        "          x)\n",
        "  x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "  x = layers.Activation('relu', name=name)(x)\n",
        "  return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyD7Dwr4PRIV"
      },
      "source": [
        "def inception(x, filters):\n",
        "    # 1x1\n",
        "    path1 = conv2d_bn(x,filters[0],1,1)\n",
        "\n",
        "    # 1x1->3x3\n",
        "    path2 = conv2d_bn(x,filters[1][0],1,1)\n",
        "    path2 = conv2d_bn(path2,filters[1][1], 3,3)\n",
        "    \n",
        "    # 1x1->5x5\n",
        "    path3 = conv2d_bn(x,filters[2][0],1,1)\n",
        "    path3 = conv2d_bn(path3,filters[2][1], 5,5)\n",
        "\n",
        "    # 3x3->1x1\n",
        "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
        "    path4 = conv2d_bn(path4,filters[3],1,1)(path4)\n",
        "\n",
        "    return Concatenate(axis=-1)([path1,path2,path3,path4])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40PCMzkk8IpE"
      },
      "source": [
        "def InceptionV3(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'):\n",
        "  \"\"\"Instantiates the Inception v3 architecture.\n",
        " \n",
        "  Note: each Keras Application expects a specific kind of input preprocessing.\n",
        "  For `InceptionV3`, call `tf.keras.applications.inception_v3.preprocess_input`\n",
        "  on your inputs before passing them to the model.\n",
        "  `inception_v3.preprocess_input` will scale input pixels between -1 and 1.\n",
        "  Args:\n",
        "    include_top: Boolean, whether to include the fully-connected\n",
        "      layer at the top, as the last layer of the network. Default to `True`.\n",
        "    weights: One of `None` (random initialization),\n",
        "      `imagenet` (pre-training on ImageNet),\n",
        "      or the path to the weights file to be loaded. Default to `imagenet`.\n",
        "    input_tensor: Optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "      to use as image input for the model. `input_tensor` is useful for sharing\n",
        "      inputs between multiple different networks. Default to None.\n",
        "    input_shape: Optional shape tuple, only to be specified\n",
        "      if `include_top` is False (otherwise the input shape\n",
        "      has to be `(299, 299, 3)` (with `channels_last` data format)\n",
        "      or `(3, 299, 299)` (with `channels_first` data format).\n",
        "      It should have exactly 3 inputs channels,\n",
        "      and width and height should be no smaller than 75.\n",
        "      E.g. `(150, 150, 3)` would be one valid value.\n",
        "      `input_shape` will be ignored if the `input_tensor` is provided.\n",
        "    pooling: Optional pooling mode for feature extraction\n",
        "      when `include_top` is `False`.\n",
        "      - `None` (default) means that the output of the model will be\n",
        "          the 4D tensor output of the last convolutional block.\n",
        "      - `avg` means that global average pooling\n",
        "          will be applied to the output of the\n",
        "          last convolutional block, and thus\n",
        "          the output of the model will be a 2D tensor.\n",
        "      - `max` means that global max pooling will be applied.\n",
        "    classes: optional number of classes to classify images\n",
        "      into, only to be specified if `include_top` is True, and\n",
        "      if no `weights` argument is specified. Default to 1000.\n",
        "    classifier_activation: A `str` or callable. The activation function to use\n",
        "      on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
        "      `classifier_activation=None` to return the logits of the \"top\" layer.\n",
        "      When loading pretrained weights, `classifier_activation` can only\n",
        "      be `None` or `\"softmax\"`.\n",
        "  Returns:\n",
        "    A `keras.Model` instance.\n",
        "  \"\"\"\n",
        "\n",
        "  # Determine proper input shape\n",
        "  input_shape = imagenet_utils.obtain_input_shape(\n",
        "      input_shape,\n",
        "      default_size=299,\n",
        "      min_size=75,\n",
        "      data_format=backend.image_data_format(),\n",
        "      require_flatten=include_top,\n",
        "      weights=weights)\n",
        "\n",
        "  if input_tensor is None:\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "  else:\n",
        "    if not backend.is_keras_tensor(input_tensor):\n",
        "      img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "    else:\n",
        "      img_input = input_tensor\n",
        "\n",
        "  if backend.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = 3\n",
        "\n",
        "  x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid') # (297-3)/2 + 1=147+1 = 148\n",
        "  x = conv2d_bn(x, 32, 3, 3, padding='valid') # (148-3)/1+1 = 146\n",
        "  x = conv2d_bn(x, 64, 3, 3) # (146+2-3)/1+1 = 146\n",
        "  x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x) # 146/2 = 73\n",
        "\n",
        "  x = conv2d_bn(x, 80, 1, 1, padding='valid') # (73-1)/1+1 = 73\n",
        "  x = conv2d_bn(x, 192, 3, 3, padding='valid') # (73-3)/1+1=71\n",
        "  x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x) # (71+2(1)-3)/2 =35\n",
        "\n",
        "  # mixed 0: 35 x 35 x 256\n",
        "  branch1x1 = conv2d_bn(x, 64, 1, 1) \n",
        "\n",
        "  branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D(\n",
        "      (3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed0')\n",
        "\n",
        "  # mixed 1: 35 x 35 x 288\n",
        "  branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "  branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D(\n",
        "      (3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed1')\n",
        "\n",
        "  # mixed 2: 35 x 35 x 288\n",
        "  branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "  branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "  branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D(\n",
        "      (3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed2')\n",
        "\n",
        "  # mixed 3: 17 x 17 x 768\n",
        "  branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "  branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "  branch3x3dbl = conv2d_bn(\n",
        "      branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "  x = layers.concatenate([branch3x3, branch3x3dbl, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed3')\n",
        "\n",
        "  # mixed 4: 17 x 17 x 768\n",
        "  branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "  branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D(\n",
        "      (3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed4')\n",
        "\n",
        "  # mixed 5, 6: 17 x 17 x 768\n",
        "  for i in range(2):\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D((3, 3),\n",
        "                                          strides=(1, 1),\n",
        "                                          padding='same')(\n",
        "                                              x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "                           axis=channel_axis,\n",
        "                           name='mixed' + str(5 + i))\n",
        "\n",
        "  # mixed 7: 17 x 17 x 768\n",
        "  branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "  branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
        "  branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "  branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "  branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "  branch_pool = layers.AveragePooling2D(\n",
        "      (3, 3), strides=(1, 1), padding='same')(x)\n",
        "  branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "  x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed7')\n",
        "\n",
        "  # mixed 8: 8 x 8 x 1280\n",
        "  branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "  branch3x3 = conv2d_bn(branch3x3, 320, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "  branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "  branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "  branch7x7x3 = conv2d_bn(\n",
        "      branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "  branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "  x = layers.concatenate([branch3x3, branch7x7x3, branch_pool],\n",
        "                         axis=channel_axis,\n",
        "                         name='mixed8')\n",
        "\n",
        "  # mixed 9: 8 x 8 x 2048\n",
        "  for i in range(2):\n",
        "    branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "    branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "    branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "    branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "    branch3x3 = layers.concatenate([branch3x3_1, branch3x3_2],\n",
        "                                   axis=channel_axis,\n",
        "                                   name='mixed9_' + str(i))\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "    branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "    branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "    branch3x3dbl = layers.concatenate([branch3x3dbl_1, branch3x3dbl_2],\n",
        "                                      axis=channel_axis)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D((3, 3),\n",
        "                                          strides=(1, 1),\n",
        "                                          padding='same')(\n",
        "                                              x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "                           axis=channel_axis,\n",
        "                           name='mixed' + str(9 + i))\n",
        "  if include_top:\n",
        "    # Classification block\n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    imagenet_utils.validate_activation(classifier_activation, weights)\n",
        "    x = layers.Dense(classes, activation=classifier_activation,\n",
        "                     name='predictions')(x)\n",
        "  else:\n",
        "    if pooling == 'avg':\n",
        "      x = layers.GlobalAveragePooling2D()(x)\n",
        "    elif pooling == 'max':\n",
        "      x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "  # Ensure that the model takes into account\n",
        "  # any potential predecessors of `input_tensor`.\n",
        "  if input_tensor is not None:\n",
        "    inputs = layer_utils.get_source_inputs(input_tensor)\n",
        "  else:\n",
        "    inputs = img_input\n",
        "  # Create model.\n",
        "  model = training.Model(inputs, x, name='inception_v3')\n",
        "\n",
        "  # Load weights.\n",
        "  if weights == 'imagenet':\n",
        "    if include_top:\n",
        "      weights_path = data_utils.get_file(\n",
        "          'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "          WEIGHTS_PATH,\n",
        "          cache_subdir='models',\n",
        "          file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n",
        "    else:\n",
        "      weights_path = data_utils.get_file(\n",
        "          'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "          WEIGHTS_PATH_NO_TOP,\n",
        "          cache_subdir='models',\n",
        "          file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n",
        "    model.load_weights(weights_path)\n",
        "  elif weights is not None:\n",
        "    model.load_weights(weights)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpd1h0km8It8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fde8f3-9f3c-40a6-90f1-a9d877982656"
      },
      "source": [
        "y = np.arange(20, 30).reshape(2, 1, 5)\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[20 21 22 23 24]]\n",
            "\n",
            " [[25 26 27 28 29]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKDIBS0K8IyJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaFoPc0F8I16"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_MwRTpz8I59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q78Z-yI8I9K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo-oZZVs8JAg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8re-VVC8JIa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2pMZF4k8JMv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiVlNNgX8JQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYz6XOJy8JUi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTz3e2o8JZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWEOeBzp8Jby"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17qzHZ1I8JfM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw043RRy8Ji3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sF8DWMB8Jmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUuT_Fu8JqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdPDy5rF8JuD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A86uczaf8JyJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGIZx92A8J2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDu4gJFf8J5t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzWBT2i88J96"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRkKs5q_8KB6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXDjRU7R8KFE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz6yjgve8KJQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5S3YFof8KMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9iFEtWf8KQU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6Q-RXM8KTl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxVhZKL68KW6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7LgKesc8Kas"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}